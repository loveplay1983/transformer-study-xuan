{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5c137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    AutoFeatureExtractor,\n",
    "    AutoTokenizer\n",
    ")\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9c098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    nltk.download(\"punkt\")\n",
    "#     nltk.download(\"punkt\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ef086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2b3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c27c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce38390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755e25540ef14ecdb26e1b9c2ecf7338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52535d311c84a08b218cc061d309928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.1.ln_cross_attn.bias', 'h.1.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.bias', 'h.2.ln_cross_attn.weight', 'h.0.ln_cross_attn.weight', 'h.7.crossattention.q_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.8.crossattention.q_attn.bias', 'h.10.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.5.crossattention.c_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.11.crossattention.q_attn.weight', 'h.9.crossattention.c_attn.weight', 'h.4.ln_cross_attn.bias', 'h.11.crossattention.c_proj.weight', 'h.10.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.10.crossattention.q_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.2.ln_cross_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.bias', 'h.4.crossattention.q_attn.weight', 'h.5.ln_cross_attn.weight', 'h.8.ln_cross_attn.weight', 'h.0.ln_cross_attn.bias', 'h.9.crossattention.c_proj.weight', 'h.6.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.8.ln_cross_attn.bias', 'h.8.crossattention.c_proj.weight', 'h.10.crossattention.c_attn.bias', 'h.1.crossattention.c_proj.weight', 'h.5.crossattention.c_proj.weight', 'h.8.crossattention.c_proj.bias', 'h.11.ln_cross_attn.bias', 'h.9.crossattention.q_attn.bias', 'h.0.crossattention.c_proj.bias', 'h.1.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.9.ln_cross_attn.bias', 'h.11.crossattention.q_attn.bias', 'h.11.ln_cross_attn.weight', 'h.9.ln_cross_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_attn.bias', 'h.3.ln_cross_attn.weight', 'h.0.crossattention.c_proj.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.q_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.10.ln_cross_attn.weight', 'h.7.ln_cross_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.2.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.0.crossattention.c_attn.weight', 'h.5.crossattention.q_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.6.crossattention.c_attn.bias', 'h.7.crossattention.c_proj.weight', 'h.4.ln_cross_attn.weight', 'h.2.crossattention.q_attn.bias', 'h.3.ln_cross_attn.bias', 'h.3.crossattention.c_proj.weight', 'h.7.ln_cross_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.7.crossattention.q_attn.bias', 'h.9.crossattention.c_attn.bias', 'h.5.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.3.crossattention.q_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.10.ln_cross_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.6.crossattention.q_attn.bias', 'h.7.crossattention.c_attn.bias', 'h.10.crossattention.c_proj.weight', 'h.3.crossattention.c_proj.bias', 'h.4.crossattention.c_attn.weight', 'h.3.crossattention.q_attn.bias', 'h.0.crossattention.c_attn.bias', 'h.6.ln_cross_attn.weight', 'h.5.ln_cross_attn.bias', 'h.0.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.6.crossattention.q_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
    "text_decode_model = \"gpt2\"\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    image_encoder_model, text_decode_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3730e969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4daf805bf674b1dad70b21ac88afab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loveplay1983/Workstation/Anaconda/anaconda/envs/torch/lib/python3.11/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# image feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\n",
    "# text tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_decode_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c6b27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# update the model config\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f704756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/tokenizer_config.json',\n",
       " '/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/special_tokens_map.json',\n",
       " '/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/vocab.json',\n",
       " '/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/merges.txt',\n",
       " '/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/added_tokens.json',\n",
       " '/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model/tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"/media/loveplay1983/training/ML/imgcap/test/vitgpt2-coco/vit-gpt-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "feature_extractor.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d35ade0",
   "metadata": {},
   "source": [
    "# COCO \n",
    "\n",
    "https://huggingface.co/datasets/ydshieh/coco_dataset_script\n",
    "https://www.v7labs.com/blog/coco-dataset-guide\n",
    "https://paperswithcode.com/dataset/coco\n",
    "https://medium.com/%E5%AD%B8%E4%BB%A5%E5%BB%A3%E6%89%8D/note-coco-dataset-1-4f306f4d5314\n",
    "https://machinelearningspace.com/coco-dataset-a-step-by-step-guide-to-loading-and-visualizing/\n",
    "https://cocodataset.org/#home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000eddc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
