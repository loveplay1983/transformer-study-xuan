{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de46be2",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7be217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import io, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# hugginface\n",
    "import datasets  # https://pypi.org/project/datasets/\n",
    "from transformers import (\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    VisionEncoderDecoderModel,\n",
    "    ViTFeatureExtractor,\n",
    "    AutoTokenizer,\n",
    "    GPT2Config,\n",
    "    default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d43a96c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available\n",
      "The GPU(s) are as follows:\n",
      "0 : NVIDIA GeForce RTX 3090\n",
      "1 : NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"There are {torch.cuda.device_count()} GPU(s) available\")\n",
    "#     print(f\"We will use the GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\"The GPU(s) are as follows:\")\n",
    "    for each in range(torch.cuda.device_count()):\n",
    "        print(f\"{each} : {torch.cuda.get_device_properties(each).name}\")\n",
    "else:\n",
    "    print(\"No GPU available, usig the CPU instead.\")\n",
    "    device = torch.device(\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023ee87",
   "metadata": {},
   "source": [
    "# Parameters, Helper functions, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25fcefee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "class config: \n",
    "    ENCODER = \"google/vit-base-patch16-224\"\n",
    "    DECODER = 'gpt2'\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    VAL_BATCH_SIZE = 1\n",
    "    VAL_EPOCHS = 1\n",
    "    LR = 5e-5\n",
    "    SEED = 42\n",
    "    MAX_LEN = 128\n",
    "    SUMMARY_LEN = 20\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    MEAN = (0.485, 0.456, 0.406)\n",
    "    STD = (0.229, 0.224, 0.225)\n",
    "    TRAIN_PCT = 0.95\n",
    "    NUM_WORKERS = mp.cpu_count() # number of logical CPU cores\n",
    "    EPOCHS = 3\n",
    "    IMG_SIZE = (224, 224)\n",
    "    LABEL_MASK = -100\n",
    "    TOP_K = 1000\n",
    "    TOP_P = 0.95 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4909710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "    \"\"\"\n",
    "    bos - begin of special \n",
    "    eos - end of special \n",
    "    \"\"\"\n",
    "    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a102c501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
