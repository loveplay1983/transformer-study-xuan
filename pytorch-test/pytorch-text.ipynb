{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ab72ca",
   "metadata": {},
   "source": [
    "# seq to seq and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b35d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31758ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1717d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ba16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0:\"SOS\", 1:\"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            # if not SOS or EOS, then the index \n",
    "            # will start from 2\n",
    "            self.word2index[word] = self.n_words\n",
    "            # The first actual word with counting\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde193a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    lines = open(\"./data/english-lang-trans/%s-%s.txt\" % (lang1, lang2),\\\n",
    "                encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in l.split(\"\\t\")] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    return input_lang, output_lang, pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7978cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the data set to only relatively short and simple sentences.\n",
    "\n",
    "MAX_LENGTH=10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc289b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s senence pairs\" % len(pairs))\n",
    "    print(\"Counting words\")\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words: \")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b7770",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"fra\", True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8dee4",
   "metadata": {},
   "source": [
    "## seq2seq working flow\n",
    "![seq2seq working flow](https://pytorch.org/tutorials/_images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d13148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    \n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b1f5d",
   "metadata": {},
   "source": [
    "![seq2seq encoding - decoding](https://pytorch.org/tutorials/_images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef977c3",
   "metadata": {},
   "source": [
    "**Understanding squeeze(-1) and Detach in Decoder Input Processing (Seq2seq with Teacher Forcing):**\n",
    "\n",
    "In a seq2seq model with teacher forcing, `squeeze(-1)` and `detach` are used together during decoder input processing to ensure proper shape compatibility and memory optimization. Here's a detailed breakdown:\n",
    "\n",
    "**1. Context and Teacher Forcing:**\n",
    "\n",
    "- Seq2seq models translate between sequences (e.g., text-to-text, speech-to-text).\n",
    "- Teacher forcing is a training technique where the model receives the correct target sequence as input at each decoding step, along with previously generated elements.\n",
    "\n",
    "**2. Decoder Input Processing:**\n",
    "\n",
    "   **a. Target Sequence Reshaping (unsqueeze(1))**\n",
    "\n",
    "     - The target sequence (ground truth) typically has a shape `(batch_size, target_length)`.\n",
    "     - For teacher forcing, the decoder needs input one element at a time during each decoding step.\n",
    "     - To achieve this, `unsqueeze(1)` is used during training:\n",
    "\n",
    "       ```python\n",
    "       # Example target sequence\n",
    "       target_sequence = torch.randint(1, 10, (batch_size, target_length))\n",
    "\n",
    "       # Teacher forcing input for first decoding step\n",
    "       teacher_forcing_input = target_sequence[:, 0].unsqueeze(1)\n",
    "       ```\n",
    "\n",
    "     - Explanation:\n",
    "       - `target_sequence[:, 0]` extracts the first element (index 0) from each sequence in the batch, resulting in a tensor of shape `(batch_size,)`.\n",
    "       - `unsqueeze(1)` inserts a new dimension of size 1 at dimension 1 (the column dimension). This creates a tensor with shape `(batch_size, 1)`, aligning with the expected decoder input format at the first step.\n",
    "\n",
    "   **b. Decoder Output Reshaping and Detachment (squeeze(-1).detach())**\n",
    "\n",
    "     - After each decoding step, the decoder generates an output.\n",
    "     - We need to compare the decoder output with the corresponding element in the target sequence for calculating the loss during training.\n",
    "     - However, the decoder output might have a shape `(batch_size, target_length, hidden_size)`:\n",
    "\n",
    "       - `batch_size`: Number of samples in the batch.\n",
    "       - `target_length`: Length of the target sequence.\n",
    "       - `hidden_size`: Model's internal hidden state dimension (representing extracted features).\n",
    "\n",
    "     ```python\n",
    "     # Example decoder output after a decoding step\n",
    "     decoder_output = model(decoder_input)  # Model processes decoder input\n",
    "\n",
    "     # Process decoder output for loss calculation\n",
    "     processed_decoder_output = decoder_output.squeeze(-1).detach()\n",
    "     ```\n",
    "\n",
    "     - Explanation:\n",
    "       - `squeeze(-1)` removes the dimension of size 1 at the last dimension (dimension -1). This ensures the decoder output has the same shape `(batch_size, target_length)` as the target sequence, allowing for element-wise comparison during loss calculation. Essentially, it extracts the meaningful content from the last dimension (`hidden_size`) by combining it with the previous dimensions (`batch_size` and `target_length`).\n",
    "       - `.detach()` detaches the processed decoder output from the computational graph. Since we're using the ground truth for teacher forcing and not backpropagating through the decoder output in this step, detaching saves memory and avoids unnecessary computations.\n",
    "\n",
    "**3. Key Points:**\n",
    "\n",
    "- `unsqueeze(1)` prepares the target sequence for teacher forcing by creating an input with the correct shape for the first decoding step.\n",
    "- `squeeze(-1).detach()` processes the decoder output by:\n",
    "   - Removing the unnecessary `hidden_size` dimension for element-wise comparison.\n",
    "   - Detaching the output from the computational graph for teacher forcing efficiency.\n",
    "\n",
    "**In essence, these operations ensure that the decoder receives the appropriate teacher forcing input and that the decoder output is properly shaped for loss calculation during training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long,\\\n",
    "                                   device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        \n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input,\n",
    "                                                               decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing, feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # teacher forcing\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach() # detach from hist as input\n",
    "                \n",
    "        decoder_outputs = torch.cat(decoer_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        # return `None` for consistency in the training loop\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "    \n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad31d4",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/1152PYf.png)  \n",
    "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250a468",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing taining data\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\", \"fra\", True)\n",
    "    \n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
    "    \n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "        \n",
    "        \n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "    \n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, \n",
    "                                  batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function to print time elapsed and estimated time remaining given the current time and progress %.\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a7f1f",
   "metadata": {},
   "source": [
    "> Change the backend to TkAgg, QtAgg, or WXAgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('QtAgg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual train, evaluation\n",
    "\n",
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention('il n est pas aussi grand que son pere')\n",
    "\n",
    "evaluateAndShowAttention('je suis trop fatigue pour conduire')\n",
    "\n",
    "evaluateAndShowAttention('je suis desole si c est une question idiote')\n",
    "\n",
    "evaluateAndShowAttention('je suis reellement fiere de vous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a094df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aead68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e7cc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ced821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fd56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504268e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03422c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f3970f",
   "metadata": {},
   "source": [
    "# preprocess custom text dataset using torchtext \n",
    "\n",
    "Read a dataset\n",
    "\n",
    "Tokenize sentence\n",
    "\n",
    "Apply transforms to sentence\n",
    "\n",
    "Perform bucket batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b83c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torchdata.datapipes as dp\n",
    "import torchtext.transforms as T\n",
    "\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "eng = spacy.load(\"en_core_web_sm\")\n",
    "zh = spacy.load(\"zh_core_web_sm\")\n",
    "de = spacy.load(\"de_core_news_sm\")\n",
    "fr = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04ab4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"data/deu-eng/deu.txt\"\n",
    "data_pipe = dp.iter.IterableWrapper([FILE_PATH])\n",
    "data_pipe = dp.iter.FileOpener(data_pipe, mode=\"rb\")\n",
    "data_pipe = data_pipe.parse_csv(skip_lines=0, delimiter=\"\\t\", as_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb4203cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSample(data_pipe):\n",
    "    for sample in data_pipe:\n",
    "        print(sample)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa90f0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'Geh.', 'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)')\n"
     ]
    }
   ],
   "source": [
    "showSample(data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9493a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAttribution(row):\n",
    "    \"\"\"\n",
    "    Keeping the first two elements in a tuple\n",
    "    Keeping the first and second columns\n",
    "    \"\"\"\n",
    "    return row[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8112316",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.map(removeAttribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f7b5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'Geh.')\n"
     ]
    }
   ],
   "source": [
    "showSample(data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af4ac89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "def engTokenize(text):\n",
    "    \"\"\"\n",
    "    tokenize an English text and return a list of tokens\n",
    "    \"\"\"\n",
    "    return [token.text for token in eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91c7864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deTokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize a German text and return a list of tokens\n",
    "    \"\"\"\n",
    "    return [token.text for token in de.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "323d093a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world', '!', '!', '!']\n",
      "['Hallo', 'Welt', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "# test for the tokenization\n",
    "print(engTokenize(\"Hello world!!!\"))\n",
    "print(deTokenize(\"Hallo Welt!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b17c8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Have', 'a', 'good', 'day', '!', '!', '!']\n",
      "['Haben', 'Sie', 'einen', 'guten', 'Tag', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(engTokenize(\"Have a good day!!!\"))\n",
    "print(deTokenize(\"Haben Sie einen guten Tag!!!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795684cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "def getTokens(data_iter, place):\n",
    "    \"\"\"\n",
    "    Function to yield tokens from an iterator. Since, our iterator contains\n",
    "    tuple of sentences (source and target), `place` parameters defines for which\n",
    "    index to return the tokens for. `place=0` for source and `place=1` for target\n",
    "    \"\"\"\n",
    "    for english, german in data_iter:\n",
    "        if place == 0:\n",
    "            yield engTokenize(english)\n",
    "        else:\n",
    "            yield deTokenize(german)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d60f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe, 0),\n",
    "    min_freq=2,\n",
    "    specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"],\n",
    "    special_first=True\n",
    ")\n",
    "source_vocab.set_default_index(source_vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c7e240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocab = build_vocab_from_iterator(\n",
    "    getTokens(data_pipe,1),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "target_vocab.set_default_index(target_vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36c9b15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<sos>', '<eos>', '<unk>', '.', 'I', 'Tom', 'to', 'you']\n"
     ]
    }
   ],
   "source": [
    "# test for vocab\n",
    "print(source_vocab.get_itos()[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b6d95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numericalize sentences using vocabulary\n",
    "# convert our sentences to corresponding indices\n",
    "def getTransform(vocab):\n",
    "    \"\"\"\n",
    "    Create transforms based on given vocabulary. The returned transform is applied to sequence\n",
    "    of tokens.\n",
    "    \"\"\"\n",
    "    text_transform = T.Sequential(\n",
    "        # converts the sentences to indices based on given vocabulary\n",
    "        T.VocabTransform(vocab=vocab),\n",
    "        ## Add <sos> at beginning of each sentence. 1 because the index for <sos> in vocabulary is\n",
    "        # 1 as seen in previous section\n",
    "        T.AddToken(1, begin=True),\n",
    "        ## Add <eos> at beginning of each sentence. 2 because the index for <eos> in vocabulary is\n",
    "        # 2 as seen in previous section\n",
    "        T.AddToken(2, begin=False)\n",
    "    )\n",
    "    return text_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6997f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5321c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32fbbbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sentence = I changed.\n",
      "Transformed sentence = [1, 5, 510, 4, 2]\n",
      "<sos>Ichanged.<eos>"
     ]
    }
   ],
   "source": [
    "temp_list = list(data_pipe)\n",
    "some_sentence = temp_list[798][0]\n",
    "print(f\"Some sentence = \", end=\"\")\n",
    "print(some_sentence)\n",
    "transformed_sentence = getTransform(source_vocab)(engTokenize(some_sentence))\n",
    "print(\"Transformed sentence = \", end=\"\")\n",
    "print(transformed_sentence)\n",
    "index_to_string = source_vocab.get_itos()\n",
    "for index in transformed_sentence:\n",
    "    print(index_to_string[index], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7090bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyTransform(sequence_pair):\n",
    "    \"\"\"\n",
    "    Apply transforms to sequence of tokens in a sequence pair\n",
    "    \"\"\"\n",
    "    \n",
    "    return (\n",
    "        getTransform(source_vocab)(engTokenize(sequence_pair[0])),\n",
    "        getTransform(target_vocab)(deTokenize(sequence_pair[1]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "916cf86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 617, 4, 2], [1, 743, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "data_pipe = data_pipe.map(applyTransform)\n",
    "temp_list = list(data_pipe)\n",
    "print(temp_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66d4f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos>Go.<eos><sos>present.<eos>"
     ]
    }
   ],
   "source": [
    "index_to_string = source_vocab.get_itos()\n",
    "for inx_list in temp_list[0]:\n",
    "#     print(index_to_string[index], end=\"\")\n",
    "    output = []\n",
    "    \n",
    "    for inx in inx_list:\n",
    "        print(index_to_string[inx], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65bbbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortBucket(bucket):\n",
    "    \"\"\"\n",
    "    Function to sort a given bucket. Here, we want to sort based on the length of\n",
    "    source and target sequence.\n",
    "    \"\"\"\n",
    "    return sorted(bucket, key=lambda x: (len(x[0]), len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8e5335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.bucketbatch(\n",
    "    batch_size = 4,\n",
    "    batch_num = 5,\n",
    "    bucket_num = 1,\n",
    "    use_in_batch_shuffle=False,\n",
    "    sort_key=sortBucket\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b019dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69473"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9307c727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1, 5393, 21, 4, 2], [1, 7035, 31, 24, 2]), ([1, 5393, 21, 4, 2], [1, 16189, 31, 24, 2]), ([1, 5, 440, 4, 2], [1, 7, 673, 4, 2]), ([1, 5, 440, 4, 2], [1, 7, 3256, 4, 2])]\n"
     ]
    }
   ],
   "source": [
    "print(list(data_pipe)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73ab36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateSourceTarget(sequence_pairs):\n",
    "    \"\"\"\n",
    "    input of form: `[(X_1,y_1), (X_2,y_2), (X_3,y_3), (X_4,y_4)]`\n",
    "    output of form: `((X_1,X_2,X_3,X_4), (y_1,y_2,y_3,y_4))`\n",
    "    \"\"\"\n",
    "    sources,targets = zip(*sequence_pairs)\n",
    "    return sources,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f351594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(([1, 1972, 69, 4, 2], [1, 617, 99, 4, 2], [1, 1044, 21, 4, 2], [1, 6923, 23, 195, 2]), ([1, 2200, 28, 24, 2], [1, 743, 106, 24, 2], [1, 375, 12, 31, 24, 2], [1, 7, 1041, 381, 24, 2]))\n"
     ]
    }
   ],
   "source": [
    "## Apply the function to each element in the iterator\n",
    "data_pipe = data_pipe.map(separateSourceTarget)\n",
    "print(list(data_pipe)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55649084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "def applyPadding(pair_of_sequences):\n",
    "    \"\"\"\n",
    "    Convert sequences to tensors and apply paddjing\n",
    "    \"\"\"\n",
    "    return (T.ToTensor(0)(list(pair_of_sequences[0])), T.ToTensor(0)(list(pair_of_sequences[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd304d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = data_pipe.map(applyPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5dbc3065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  index to string mapping to see how the sequence would look with tokens instead of indices\n",
    "\n",
    "source_index_to_string = source_vocab.get_itos()\n",
    "target_index_to_string = target_vocab.get_itos()\n",
    "\n",
    "\n",
    "def showSomeTransformedSentences(data_pipe):\n",
    "    \"\"\"\n",
    "    Function to show how the sentences look like after applying all transforms.\n",
    "    Here we try to print actual words instead of corresponding index\n",
    "    \"\"\"\n",
    "    for sources,targets in data_pipe:\n",
    "        if sources[0][-1] != 0:\n",
    "            continue # Just to visualize padding of shorter sentences\n",
    "        for i in range(4):\n",
    "            source = \"\"\n",
    "            for token in sources[i]:\n",
    "                source += \" \" + source_index_to_string[token]\n",
    "            target = \"\"\n",
    "            for token in targets[i]:\n",
    "                target += \" \" + target_index_to_string[token]\n",
    "            print(f\"Source: {source}\")\n",
    "            print(f\"Target: {target}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77efb99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:  <sos> I spit . <eos> <pad>\n",
      "Target:  <sos> Ich habe gespuckt . <eos>\n",
      "Source:  <sos> I wept . <eos> <pad>\n",
      "Target:  <sos> Ich habe geweint . <eos>\n",
      "Source:  <sos> I 'm 19 . <eos>\n",
      "Target:  <sos> Ich bin 19. <eos> <pad>\n",
      "Source:  <sos> I 'm OK . <eos>\n",
      "Target:  <sos> Mir geht's gut . <eos>\n"
     ]
    }
   ],
   "source": [
    "showSomeTransformedSentences(data_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f2fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce04c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f51d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32e471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6ff75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "418a1c54",
   "metadata": {},
   "source": [
    "# Text classification with the torchtext library\n",
    "`!pip install -U portalocker>=2.0.0``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8fe588ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b3faa943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(AG_NEWS(split=\"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "82046ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")\n",
      "(3, 'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.')\n",
      "(3, \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\")\n",
      "(3, 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.')\n",
      "(3, 'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.')\n",
      "(3, 'Stocks End Up, But Near Year Lows (Reuters) Reuters - Stocks ended slightly higher on Friday\\\\but stayed near lows for the year as oil prices surged past  #36;46\\\\a barrel, offsetting a positive outlook from computer maker\\\\Dell Inc. (DELL.O)')\n",
      "(3, \"Money Funds Fell in Latest Week (AP) AP - Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, the Investment Company Institute said Thursday.\")\n",
      "(3, 'Fed minutes show dissent over inflation (USATODAY.com) USATODAY.com - Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, indicating the economy is improving from a midsummer slump.')\n",
      "(3, 'Safety Net (Forbes.com) Forbes.com - After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm at an annual base salary of  #36;70,000. Soon after, a financial planner stopped by his desk to drop off brochures about insurance benefits available through his employer. But, at 32, \"buying insurance was the furthest thing from my mind,\" says Riley.')\n",
      "(3, \"Wall St. Bears Claw Back Into the Black  NEW YORK (Reuters) - Short-sellers, Wall Street's dwindling  band of ultra-cynics, are seeing green again.\")\n",
      "(3, \"Oil and Economy Cloud Stocks' Outlook  NEW YORK (Reuters) - Soaring crude prices plus worries  about the economy and the outlook for earnings are expected to  hang over the stock market next week during the depth of the  summer doldrums.\")\n",
      "(3, \"No Need for OPEC to Pump More-Iran Gov  TEHRAN (Reuters) - OPEC can do nothing to douse scorching  oil prices when markets are already oversupplied by 2.8 million  barrels per day (bpd) of crude, Iran's OPEC governor said  Saturday, warning that prices could fall sharply.\")\n",
      "(3, 'Non-OPEC Nations Should Up Output-Purnomo  JAKARTA (Reuters) - Non-OPEC oil exporters should consider  increasing output to cool record crude prices, OPEC President  Purnomo Yusgiantoro said on Sunday.')\n",
      "(3, \"Google IPO Auction Off to Rocky Start  WASHINGTON/NEW YORK (Reuters) - The auction for Google  Inc.'s highly anticipated initial public offering got off to a  rocky start on Friday after the Web search company sidestepped  a bullet from U.S. securities regulators.\")\n",
      "(3, \"Dollar Falls Broadly on Record Trade Gap  NEW YORK (Reuters) - The dollar tumbled broadly on Friday  after data showing a record U.S. trade deficit in June cast  fresh doubts on the economy's recovery and its ability to draw  foreign capital to fund the growing gap.\")\n",
      "(3, \"Rescuing an Old Saver If you think you may need to help your elderly relatives with their finances, don't be shy about having the money talk -- soon.\")\n",
      "(3, 'Kids Rule for Back-to-School The purchasing power of kids is a big part of why the back-to-school season has become such a huge marketing phenomenon.')\n",
      "(3, \"In a Down Market, Head Toward Value Funds There is little cause for celebration in the stock market these days, but investors in value-focused mutual funds have reason to feel a bit smug -- if only because they've lost less than the folks who stuck with growth.\")\n",
      "(3, 'US trade deficit swells in June The US trade deficit has exploded 19 to a record \\\\$55.8bn as oil costs drove imports higher, according to a latest figures.')\n",
      "(3, \"Shell 'could be target for Total' Oil giant Shell could be bracing itself for a takeover attempt, possibly from French rival Total, a  press report claims.\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(next(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "79290ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2f10d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "train_iter = AG_NEWS(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5071a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dbb4528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8be0bbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 30, 5297]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e97f35f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12544, 9199, 6, 269]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([\"hello\", \"gears\", \"of\", \"war\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bb944056",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b52ea93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[475, 21, 2, 30, 5297]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "72a5cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pipeline('10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fe037801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "72eaf109",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9156e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [],[],[0]\n",
    "    for _label, _text in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
