{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f01789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbbec66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de8bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf6e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X[N,C,H,W]: torch.Size([32, 1, 28, 28])\n",
      "Sahep of y:torch.Size([32]) torch.int64 \n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X[N,C,H,W]: {X.shape}\")\n",
    "    print(f\"Sahep of y:{y.shape} {y.dtype} \")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ab7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde606cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68589108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf938ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (op1): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (opt2): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.op1 = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        self.opt2 = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.op1(x)\n",
    "        logits = self.opt2(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714da3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9421c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea2f25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b447f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}|{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5530cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db7514a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307558 [   32|60000]\n",
      "loss: 0.931989 [ 3232|60000]\n",
      "loss: 0.558470 [ 6432|60000]\n",
      "loss: 0.840598 [ 9632|60000]\n",
      "loss: 0.471746 [12832|60000]\n",
      "loss: 0.795171 [16032|60000]\n",
      "loss: 0.436261 [19232|60000]\n",
      "loss: 0.275171 [22432|60000]\n",
      "loss: 0.699787 [25632|60000]\n",
      "loss: 0.450464 [28832|60000]\n",
      "loss: 0.640673 [32032|60000]\n",
      "loss: 0.462956 [35232|60000]\n",
      "loss: 0.343907 [38432|60000]\n",
      "loss: 0.608807 [41632|60000]\n",
      "loss: 0.812741 [44832|60000]\n",
      "loss: 0.443883 [48032|60000]\n",
      "loss: 0.506224 [51232|60000]\n",
      "loss: 0.598588 [54432|60000]\n",
      "loss: 0.578737 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.421679 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.368852 [   32|60000]\n",
      "loss: 0.418959 [ 3232|60000]\n",
      "loss: 0.243965 [ 6432|60000]\n",
      "loss: 0.397855 [ 9632|60000]\n",
      "loss: 0.285599 [12832|60000]\n",
      "loss: 0.584710 [16032|60000]\n",
      "loss: 0.311290 [19232|60000]\n",
      "loss: 0.314421 [22432|60000]\n",
      "loss: 0.412773 [25632|60000]\n",
      "loss: 0.295507 [28832|60000]\n",
      "loss: 0.566209 [32032|60000]\n",
      "loss: 0.571197 [35232|60000]\n",
      "loss: 0.300802 [38432|60000]\n",
      "loss: 0.699585 [41632|60000]\n",
      "loss: 0.619950 [44832|60000]\n",
      "loss: 0.587768 [48032|60000]\n",
      "loss: 0.234542 [51232|60000]\n",
      "loss: 0.342344 [54432|60000]\n",
      "loss: 0.633981 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.404645 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.349314 [   32|60000]\n",
      "loss: 0.285494 [ 3232|60000]\n",
      "loss: 0.229982 [ 6432|60000]\n",
      "loss: 0.344803 [ 9632|60000]\n",
      "loss: 0.311484 [12832|60000]\n",
      "loss: 0.663341 [16032|60000]\n",
      "loss: 0.243357 [19232|60000]\n",
      "loss: 0.222515 [22432|60000]\n",
      "loss: 0.451413 [25632|60000]\n",
      "loss: 0.355188 [28832|60000]\n",
      "loss: 0.490385 [32032|60000]\n",
      "loss: 0.417988 [35232|60000]\n",
      "loss: 0.266593 [38432|60000]\n",
      "loss: 0.442241 [41632|60000]\n",
      "loss: 0.682543 [44832|60000]\n",
      "loss: 0.734582 [48032|60000]\n",
      "loss: 0.270353 [51232|60000]\n",
      "loss: 0.392608 [54432|60000]\n",
      "loss: 0.599486 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.385371 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.233671 [   32|60000]\n",
      "loss: 0.256770 [ 3232|60000]\n",
      "loss: 0.286217 [ 6432|60000]\n",
      "loss: 0.448384 [ 9632|60000]\n",
      "loss: 0.303754 [12832|60000]\n",
      "loss: 0.613127 [16032|60000]\n",
      "loss: 0.280159 [19232|60000]\n",
      "loss: 0.258552 [22432|60000]\n",
      "loss: 0.577230 [25632|60000]\n",
      "loss: 0.297003 [28832|60000]\n",
      "loss: 0.357291 [32032|60000]\n",
      "loss: 0.417680 [35232|60000]\n",
      "loss: 0.216109 [38432|60000]\n",
      "loss: 0.444371 [41632|60000]\n",
      "loss: 0.668726 [44832|60000]\n",
      "loss: 0.331737 [48032|60000]\n",
      "loss: 0.237297 [51232|60000]\n",
      "loss: 0.348941 [54432|60000]\n",
      "loss: 0.515319 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.375986 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.254480 [   32|60000]\n",
      "loss: 0.306412 [ 3232|60000]\n",
      "loss: 0.191126 [ 6432|60000]\n",
      "loss: 0.330140 [ 9632|60000]\n",
      "loss: 0.379242 [12832|60000]\n",
      "loss: 0.532018 [16032|60000]\n",
      "loss: 0.307479 [19232|60000]\n",
      "loss: 0.161379 [22432|60000]\n",
      "loss: 0.436566 [25632|60000]\n",
      "loss: 0.221724 [28832|60000]\n",
      "loss: 0.370874 [32032|60000]\n",
      "loss: 0.239025 [35232|60000]\n",
      "loss: 0.313213 [38432|60000]\n",
      "loss: 0.500099 [41632|60000]\n",
      "loss: 0.478436 [44832|60000]\n",
      "loss: 0.564661 [48032|60000]\n",
      "loss: 0.228832 [51232|60000]\n",
      "loss: 0.313397 [54432|60000]\n",
      "loss: 0.404258 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.384825 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.234754 [   32|60000]\n",
      "loss: 0.234769 [ 3232|60000]\n",
      "loss: 0.204557 [ 6432|60000]\n",
      "loss: 0.326969 [ 9632|60000]\n",
      "loss: 0.262240 [12832|60000]\n",
      "loss: 0.477362 [16032|60000]\n",
      "loss: 0.252049 [19232|60000]\n",
      "loss: 0.183043 [22432|60000]\n",
      "loss: 0.357185 [25632|60000]\n",
      "loss: 0.244693 [28832|60000]\n",
      "loss: 0.420243 [32032|60000]\n",
      "loss: 0.383993 [35232|60000]\n",
      "loss: 0.310327 [38432|60000]\n",
      "loss: 0.427186 [41632|60000]\n",
      "loss: 0.522180 [44832|60000]\n",
      "loss: 0.365385 [48032|60000]\n",
      "loss: 0.291278 [51232|60000]\n",
      "loss: 0.338712 [54432|60000]\n",
      "loss: 0.353390 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.386789 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.233899 [   32|60000]\n",
      "loss: 0.242802 [ 3232|60000]\n",
      "loss: 0.227265 [ 6432|60000]\n",
      "loss: 0.436639 [ 9632|60000]\n",
      "loss: 0.201120 [12832|60000]\n",
      "loss: 0.665044 [16032|60000]\n",
      "loss: 0.253233 [19232|60000]\n",
      "loss: 0.254420 [22432|60000]\n",
      "loss: 0.523864 [25632|60000]\n",
      "loss: 0.316782 [28832|60000]\n",
      "loss: 0.354958 [32032|60000]\n",
      "loss: 0.298754 [35232|60000]\n",
      "loss: 0.203538 [38432|60000]\n",
      "loss: 0.365740 [41632|60000]\n",
      "loss: 0.633594 [44832|60000]\n",
      "loss: 0.473240 [48032|60000]\n",
      "loss: 0.251222 [51232|60000]\n",
      "loss: 0.421847 [54432|60000]\n",
      "loss: 0.376064 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.379910 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.241615 [   32|60000]\n",
      "loss: 0.289426 [ 3232|60000]\n",
      "loss: 0.288937 [ 6432|60000]\n",
      "loss: 0.352892 [ 9632|60000]\n",
      "loss: 0.299065 [12832|60000]\n",
      "loss: 0.496269 [16032|60000]\n",
      "loss: 0.240136 [19232|60000]\n",
      "loss: 0.159530 [22432|60000]\n",
      "loss: 0.417733 [25632|60000]\n",
      "loss: 0.325232 [28832|60000]\n",
      "loss: 0.458974 [32032|60000]\n",
      "loss: 0.271595 [35232|60000]\n",
      "loss: 0.286982 [38432|60000]\n",
      "loss: 0.453438 [41632|60000]\n",
      "loss: 0.734548 [44832|60000]\n",
      "loss: 0.379763 [48032|60000]\n",
      "loss: 0.234443 [51232|60000]\n",
      "loss: 0.354178 [54432|60000]\n",
      "loss: 0.338415 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.369434 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.219039 [   32|60000]\n",
      "loss: 0.259094 [ 3232|60000]\n",
      "loss: 0.174241 [ 6432|60000]\n",
      "loss: 0.290777 [ 9632|60000]\n",
      "loss: 0.379956 [12832|60000]\n",
      "loss: 0.504657 [16032|60000]\n",
      "loss: 0.245722 [19232|60000]\n",
      "loss: 0.168686 [22432|60000]\n",
      "loss: 0.299568 [25632|60000]\n",
      "loss: 0.205540 [28832|60000]\n",
      "loss: 0.418223 [32032|60000]\n",
      "loss: 0.141133 [35232|60000]\n",
      "loss: 0.243921 [38432|60000]\n",
      "loss: 0.394531 [41632|60000]\n",
      "loss: 0.729515 [44832|60000]\n",
      "loss: 0.406382 [48032|60000]\n",
      "loss: 0.172455 [51232|60000]\n",
      "loss: 0.398451 [54432|60000]\n",
      "loss: 0.327567 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.376369 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.216774 [   32|60000]\n",
      "loss: 0.219451 [ 3232|60000]\n",
      "loss: 0.196433 [ 6432|60000]\n",
      "loss: 0.297268 [ 9632|60000]\n",
      "loss: 0.277796 [12832|60000]\n",
      "loss: 0.364457 [16032|60000]\n",
      "loss: 0.306512 [19232|60000]\n",
      "loss: 0.182205 [22432|60000]\n",
      "loss: 0.500412 [25632|60000]\n",
      "loss: 0.242555 [28832|60000]\n",
      "loss: 0.408339 [32032|60000]\n",
      "loss: 0.125114 [35232|60000]\n",
      "loss: 0.310177 [38432|60000]\n",
      "loss: 0.495407 [41632|60000]\n",
      "loss: 0.562947 [44832|60000]\n",
      "loss: 0.361945 [48032|60000]\n",
      "loss: 0.213263 [51232|60000]\n",
      "loss: 0.382510 [54432|60000]\n",
      "loss: 0.339831 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.364236 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.173233 [   32|60000]\n",
      "loss: 0.289724 [ 3232|60000]\n",
      "loss: 0.269483 [ 6432|60000]\n",
      "loss: 0.348295 [ 9632|60000]\n",
      "loss: 0.329524 [12832|60000]\n",
      "loss: 0.549069 [16032|60000]\n",
      "loss: 0.188084 [19232|60000]\n",
      "loss: 0.189461 [22432|60000]\n",
      "loss: 0.351860 [25632|60000]\n",
      "loss: 0.202082 [28832|60000]\n",
      "loss: 0.287834 [32032|60000]\n",
      "loss: 0.086667 [35232|60000]\n",
      "loss: 0.463419 [38432|60000]\n",
      "loss: 0.439136 [41632|60000]\n",
      "loss: 0.677310 [44832|60000]\n",
      "loss: 0.465454 [48032|60000]\n",
      "loss: 0.318384 [51232|60000]\n",
      "loss: 0.368156 [54432|60000]\n",
      "loss: 0.423391 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.384216 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.236030 [   32|60000]\n",
      "loss: 0.275042 [ 3232|60000]\n",
      "loss: 0.266205 [ 6432|60000]\n",
      "loss: 0.264108 [ 9632|60000]\n",
      "loss: 0.264068 [12832|60000]\n",
      "loss: 0.564394 [16032|60000]\n",
      "loss: 0.239686 [19232|60000]\n",
      "loss: 0.138805 [22432|60000]\n",
      "loss: 0.341463 [25632|60000]\n",
      "loss: 0.199692 [28832|60000]\n",
      "loss: 0.417780 [32032|60000]\n",
      "loss: 0.304813 [35232|60000]\n",
      "loss: 0.262990 [38432|60000]\n",
      "loss: 0.287466 [41632|60000]\n",
      "loss: 0.465794 [44832|60000]\n",
      "loss: 0.510390 [48032|60000]\n",
      "loss: 0.244656 [51232|60000]\n",
      "loss: 0.250690 [54432|60000]\n",
      "loss: 0.376305 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.376763 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.253559 [   32|60000]\n",
      "loss: 0.199703 [ 3232|60000]\n",
      "loss: 0.186658 [ 6432|60000]\n",
      "loss: 0.249176 [ 9632|60000]\n",
      "loss: 0.305197 [12832|60000]\n",
      "loss: 0.420420 [16032|60000]\n",
      "loss: 0.170915 [19232|60000]\n",
      "loss: 0.154837 [22432|60000]\n",
      "loss: 0.416985 [25632|60000]\n",
      "loss: 0.197276 [28832|60000]\n",
      "loss: 0.491863 [32032|60000]\n",
      "loss: 0.114978 [35232|60000]\n",
      "loss: 0.388612 [38432|60000]\n",
      "loss: 0.252984 [41632|60000]\n",
      "loss: 0.402658 [44832|60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.296635 [48032|60000]\n",
      "loss: 0.203942 [51232|60000]\n",
      "loss: 0.279104 [54432|60000]\n",
      "loss: 0.304270 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.377663 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.225928 [   32|60000]\n",
      "loss: 0.272136 [ 3232|60000]\n",
      "loss: 0.178136 [ 6432|60000]\n",
      "loss: 0.252544 [ 9632|60000]\n",
      "loss: 0.253056 [12832|60000]\n",
      "loss: 0.363465 [16032|60000]\n",
      "loss: 0.186752 [19232|60000]\n",
      "loss: 0.109273 [22432|60000]\n",
      "loss: 0.500203 [25632|60000]\n",
      "loss: 0.217911 [28832|60000]\n",
      "loss: 0.304896 [32032|60000]\n",
      "loss: 0.154525 [35232|60000]\n",
      "loss: 0.278711 [38432|60000]\n",
      "loss: 0.352111 [41632|60000]\n",
      "loss: 0.434249 [44832|60000]\n",
      "loss: 0.281522 [48032|60000]\n",
      "loss: 0.205436 [51232|60000]\n",
      "loss: 0.238117 [54432|60000]\n",
      "loss: 0.388413 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.393863 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.145764 [   32|60000]\n",
      "loss: 0.234216 [ 3232|60000]\n",
      "loss: 0.130685 [ 6432|60000]\n",
      "loss: 0.390163 [ 9632|60000]\n",
      "loss: 0.350711 [12832|60000]\n",
      "loss: 0.507968 [16032|60000]\n",
      "loss: 0.192296 [19232|60000]\n",
      "loss: 0.106649 [22432|60000]\n",
      "loss: 0.319471 [25632|60000]\n",
      "loss: 0.267522 [28832|60000]\n",
      "loss: 0.458713 [32032|60000]\n",
      "loss: 0.146764 [35232|60000]\n",
      "loss: 0.266127 [38432|60000]\n",
      "loss: 0.336096 [41632|60000]\n",
      "loss: 0.588367 [44832|60000]\n",
      "loss: 0.390289 [48032|60000]\n",
      "loss: 0.205590 [51232|60000]\n",
      "loss: 0.282436 [54432|60000]\n",
      "loss: 0.215346 [57632|60000]\n",
      "Test Error: \n",
      " Accuracy: 87.5%, Avg loss: 0.382100 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e06fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a2c8e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b42da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7163e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b118a4d9",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d023fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b4be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19faa1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones tensor: {x_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f042b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "x_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d88e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(rand_tensor, ones_tensor, zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ddcf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1530a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape, tensor.dtype, tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        x = tensor.to(\"cuda\")\n",
    "    else:\n",
    "        x = tensor.to(\"cpu\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fecc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_cuda(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72ee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(f\"first row: {tensor[0]}\")\n",
    "print(f\"first column: {tensor[:, 0]}\")\n",
    "print(f\"last column: {tensor[..., -1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65123867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[:,1]=0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4eac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e58f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication \n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "y3 = torch.rand_like(y1)\n",
    "y4 = torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "print(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f22134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# element wise\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4264c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b428024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inplace operation\n",
    "print(tensor.add_(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with numpy\n",
    "t  = torch.ones(5)\n",
    "n = t.numpy()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c69014",
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15460731",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(t)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d29b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2777d16",
   "metadata": {},
   "source": [
    "# Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36197733",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3,3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_index = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_index]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset \n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ecaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 annotations_file, \n",
    "                 img_dir, \n",
    "                 transform=None,\n",
    "                 target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, \n",
    "                                self.img_labels.iloc[idx,0])\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, \n",
    "                              batch_size=64, \n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(test_data,\n",
    "                             batch_size=64,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafa74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display image and label by DataLoader and in-built dataset\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad871b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "print(img.size(), label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b48b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71da5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "057e1526",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6381a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y:torch.zeros(10,dtype=torch.float).scatter_(0,\n",
    "                                                                                torch.tensor(y),\n",
    "                                                                                value=1)\n",
    "                           )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab5867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028e843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84ee3732",
   "metadata": {},
   "source": [
    "# Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac01a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb9e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1,28,28,device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715607af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dceaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b417148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f6f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da296d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614143f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "print(f\"Model structure: {model}\")\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abefaaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18536245",
   "metadata": {},
   "source": [
    "# Automatic differentiation with `torch.autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)\n",
    "y = torch.zeros(3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn(5,3,requires_grad=True)\n",
    "b = torch.rand(3, requires_grad=True)\n",
    "z = torch.matmul(x,w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3249ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "print(w.grad,'\\n',b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling the gradient tracking\n",
    "z = torch.matmul(x,w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "    print(z.requires_grad_)\n",
    "    print(z.requires_grad)\n",
    "    \n",
    "    \n",
    "# or we can use detach method\n",
    "z = torch.matmul(x,w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65e413",
   "metadata": {},
   "outputs": [],
   "source": [
    "(inp+1).pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07909465",
   "metadata": {},
   "outputs": [],
   "source": [
    "(inp+1).pow(2).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadd555",
   "metadata": {},
   "outputs": [],
   "source": [
    "(inp+1).pow(2).t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe33b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (inp+1).pow(2).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862abb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547cfb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4392b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSecond call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d5bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55998409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcca940d",
   "metadata": {},
   "source": [
    "# Parameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e975350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e775d8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "OptimizedModule(\n",
      "  (_orig_mod): NeuralNetwork(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (linear_relu_stack): Sequential(\n",
      "      (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model_ = NeuralNetwork()\n",
    "model = torch.compile(model_, backend=\"aot_eager\").to(device)\n",
    "print(model_)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157f0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38fcf079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb50c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c411cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ae7e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch._dynamo.config.verbose=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ddf0e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.315061  [   64/60000]\n",
      "loss: 2.298668  [ 6464/60000]\n",
      "loss: 2.273940  [12864/60000]\n",
      "loss: 2.256106  [19264/60000]\n",
      "loss: 2.250988  [25664/60000]\n",
      "loss: 2.225804  [32064/60000]\n",
      "loss: 2.235341  [38464/60000]\n",
      "loss: 2.211386  [44864/60000]\n",
      "loss: 2.197287  [51264/60000]\n",
      "loss: 2.159976  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.6%, Avg loss: 2.159655 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.171071  [   64/60000]\n",
      "loss: 2.161341  [ 6464/60000]\n",
      "loss: 2.102017  [12864/60000]\n",
      "loss: 2.114500  [19264/60000]\n",
      "loss: 2.069915  [25664/60000]\n",
      "loss: 2.013686  [32064/60000]\n",
      "loss: 2.043946  [38464/60000]\n",
      "loss: 1.972373  [44864/60000]\n",
      "loss: 1.972247  [51264/60000]\n",
      "loss: 1.904315  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.5%, Avg loss: 1.900067 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.924569  [   64/60000]\n",
      "loss: 1.900396  [ 6464/60000]\n",
      "loss: 1.783905  [12864/60000]\n",
      "loss: 1.828985  [19264/60000]\n",
      "loss: 1.708629  [25664/60000]\n",
      "loss: 1.662768  [32064/60000]\n",
      "loss: 1.684664  [38464/60000]\n",
      "loss: 1.583880  [44864/60000]\n",
      "loss: 1.608989  [51264/60000]\n",
      "loss: 1.506278  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.520847 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.576975  [   64/60000]\n",
      "loss: 1.549084  [ 6464/60000]\n",
      "loss: 1.398985  [12864/60000]\n",
      "loss: 1.473116  [19264/60000]\n",
      "loss: 1.339000  [25664/60000]\n",
      "loss: 1.341594  [32064/60000]\n",
      "loss: 1.350105  [38464/60000]\n",
      "loss: 1.273055  [44864/60000]\n",
      "loss: 1.311504  [51264/60000]\n",
      "loss: 1.214740  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.240552 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.309324  [   64/60000]\n",
      "loss: 1.298261  [ 6464/60000]\n",
      "loss: 1.133844  [12864/60000]\n",
      "loss: 1.241552  [19264/60000]\n",
      "loss: 1.106781  [25664/60000]\n",
      "loss: 1.138213  [32064/60000]\n",
      "loss: 1.154322  [38464/60000]\n",
      "loss: 1.087851  [44864/60000]\n",
      "loss: 1.132489  [51264/60000]\n",
      "loss: 1.055331  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.074339 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.135002  [   64/60000]\n",
      "loss: 1.145130  [ 6464/60000]\n",
      "loss: 0.965934  [12864/60000]\n",
      "loss: 1.103807  [19264/60000]\n",
      "loss: 0.969600  [25664/60000]\n",
      "loss: 1.006884  [32064/60000]\n",
      "loss: 1.039705  [38464/60000]\n",
      "loss: 0.975034  [44864/60000]\n",
      "loss: 1.019932  [51264/60000]\n",
      "loss: 0.959197  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.8%, Avg loss: 0.970466 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.016709  [   64/60000]\n",
      "loss: 1.048520  [ 6464/60000]\n",
      "loss: 0.853970  [12864/60000]\n",
      "loss: 1.013846  [19264/60000]\n",
      "loss: 0.885889  [25664/60000]\n",
      "loss: 0.916325  [32064/60000]\n",
      "loss: 0.966194  [38464/60000]\n",
      "loss: 0.903395  [44864/60000]\n",
      "loss: 0.943292  [51264/60000]\n",
      "loss: 0.895049  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.900277 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.930905  [   64/60000]\n",
      "loss: 0.982133  [ 6464/60000]\n",
      "loss: 0.774520  [12864/60000]\n",
      "loss: 0.950378  [19264/60000]\n",
      "loss: 0.830268  [25664/60000]\n",
      "loss: 0.850406  [32064/60000]\n",
      "loss: 0.914394  [38464/60000]\n",
      "loss: 0.855721  [44864/60000]\n",
      "loss: 0.888049  [51264/60000]\n",
      "loss: 0.848511  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.3%, Avg loss: 0.849655 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.865133  [   64/60000]\n",
      "loss: 0.932498  [ 6464/60000]\n",
      "loss: 0.714984  [12864/60000]\n",
      "loss: 0.903436  [19264/60000]\n",
      "loss: 0.790257  [25664/60000]\n",
      "loss: 0.800856  [32064/60000]\n",
      "loss: 0.874938  [38464/60000]\n",
      "loss: 0.822660  [44864/60000]\n",
      "loss: 0.846663  [51264/60000]\n",
      "loss: 0.812574  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.811136 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.812830  [   64/60000]\n",
      "loss: 0.892775  [ 6464/60000]\n",
      "loss: 0.668555  [12864/60000]\n",
      "loss: 0.867080  [19264/60000]\n",
      "loss: 0.759713  [25664/60000]\n",
      "loss: 0.762666  [32064/60000]\n",
      "loss: 0.843157  [38464/60000]\n",
      "loss: 0.798480  [44864/60000]\n",
      "loss: 0.814239  [51264/60000]\n",
      "loss: 0.783484  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.780432 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf89ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260d92f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fea15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a949deb",
   "metadata": {},
   "source": [
    "# Save and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27ff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555d824",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models.vgg16()\n",
    "model.load_state_dict(torch.load(\"./model_weights.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d5920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save entire model\n",
    "torch.save(model, \"model.younameit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3992dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model.younameit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360b7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "105f95d2",
   "metadata": {},
   "source": [
    "# Torch.compile \n",
    "\n",
    "\n",
    "```\n",
    "Signature:\n",
    "torch.compile(\n",
    "    model: Optional[Callable] = None,\n",
    "    *,\n",
    "    fullgraph: bool = False,\n",
    "    dynamic: Optional[bool] = None,\n",
    "    backend: Union[str, Callable] = 'inductor',\n",
    "    mode: Optional[str] = None,\n",
    "    options: Optional[Dict[str, Union[str, int, bool]]] = None,\n",
    "    disable: bool = False,\n",
    ") -> Callable\n",
    "Docstring:\n",
    "Optimizes given model/function using TorchDynamo and specified backend.\n",
    "\n",
    "Concretely, for every frame executed within the compiled region, we will attempt\n",
    "to compile it and cache the compiled result on the code object for future\n",
    "use.  A single frame may be compiled multiple times if previous compiled\n",
    "results are not applicable for subsequent calls (this is called a \"guard\n",
    "failure), you can use TORCH_LOGS=guards to debug these situations.\n",
    "Multiple compiled results can be associated with a frame up to\n",
    "``torch._dynamo.config.cache_size_limit``, which defaults to 64; at which\n",
    "point we will fall back to eager.  Note that compile caches are per\n",
    "*code object*, not frame; if you dynamically create multiple copies of a\n",
    "function, they will all share the same code cache.\n",
    "\n",
    "Args:\n",
    "   model (Callable): Module/function to optimize\n",
    "   fullgraph (bool): If False (default), torch.compile attempts to discover compileable regions\n",
    "    in the function that it will optimize. If True, then we require that the entire function be\n",
    "    capturable into a single graph. If this is not possible (that is, if there are graph breaks),\n",
    "    then this will raise an error.\n",
    "   dynamic (bool or None): Use dynamic shape tracing.  When this is True, we will up-front attempt\n",
    "    to generate a kernel that is as dynamic as possible to avoid recompilations when\n",
    "    sizes change.  This may not always work as some operations/optimizations will\n",
    "    force specialization; use TORCH_LOGS=dynamic to debug overspecialization.\n",
    "    When this is False, we will NEVER generate dynamic kernels, we will always specialize.\n",
    "    By default (None), we automatically detect if dynamism has occurred and compile a more\n",
    "    dynamic kernel upon recompile.\n",
    "   backend (str or Callable): backend to be used\n",
    "\n",
    "    - \"inductor\" is the default backend, which is a good balance between performance and overhead\n",
    "\n",
    "    - Non experimental in-tree backends can be seen with `torch._dynamo.list_backends()`\n",
    "\n",
    "    - Experimental or debug in-tree backends can be seen with `torch._dynamo.list_backends(None)`\n",
    "\n",
    "    - To register an out-of-tree custom backend: https://pytorch.org/docs/main/compile/custom-backends.html\n",
    "   mode (str): Can be either \"default\", \"reduce-overhead\", \"max-autotune\" or \"max-autotune-no-cudagraphs\"\n",
    "\n",
    "    - \"default\" is the default mode, which is a good balance between performance and overhead\n",
    "\n",
    "    - \"reduce-overhead\" is a mode that reduces the overhead of python with CUDA graphs,\n",
    "      useful for small batches.  Reduction of overhead can come at the cost of more memory\n",
    "      usage, as we will cache the workspace memory required for the invocation so that we\n",
    "      do not have to reallocate it on subsequent runs.  Reduction of overhead is not guaranteed\n",
    "      to work; today, we only reduce overhead for CUDA only graphs which do not mutate inputs.\n",
    "      There are other circumstances where CUDA graphs are not applicable; use TORCH_LOG=perf_hints\n",
    "      to debug.\n",
    "\n",
    "    - \"max-autotune\" is a mode that leverages Triton based matrix multiplications and convolutions\n",
    "      It enables CUDA graphs by default.\n",
    "\n",
    "    - \"max-autotune-no-cudagraphs\" is a mode similar to \"max-autotune\" but without CUDA graphs\n",
    "\n",
    "    - To see the exact configs that each mode sets you can call `torch._inductor.list_mode_options()`\n",
    "\n",
    "   options (dict): A dictionary of options to pass to the backend. Some notable ones to try out are\n",
    "\n",
    "    - `epilogue_fusion` which fuses pointwise ops into templates. Requires `max_autotune` to also be set\n",
    "\n",
    "    - `max_autotune` which will profile to pick the best matmul configuration\n",
    "\n",
    "    - `fallback_random` which is useful when debugging accuracy issues\n",
    "\n",
    "    - `shape_padding` which pads matrix shapes to better align loads on GPUs especially for tensor cores\n",
    "\n",
    "    - `triton.cudagraphs` which will reduce the overhead of python with CUDA graphs\n",
    "\n",
    "    - `trace.enabled` which is the most useful debugging flag to turn on\n",
    "\n",
    "    - `trace.graph_diagram` which will show you a picture of your graph after fusion\n",
    "\n",
    "    - For inductor you can see the full list of configs that it supports by calling `torch._inductor.list_options()`\n",
    "   disable (bool): Turn torch.compile() into a no-op for testing\n",
    "\n",
    "Example::\n",
    "\n",
    "    @torch.compile(options={\"triton.cudagraphs\": True}, fullgraph=True)\n",
    "    def foo(x):\n",
    "        return torch.sin(x) + torch.cos(x)\n",
    "File:      ~/workstation/AI/utils/Anaconda3/envs/torch/lib/python3.11/site-packages/torch/__init__.py\n",
    "Type:      function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6226b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c092c8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cudagraphs', 'inductor', 'onnxrt', 'openxla', 'openxla_eval', 'tvm']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8678832f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aot_eager',\n",
       " 'aot_eager_decomp_partition',\n",
       " 'aot_eager_default_partitioner',\n",
       " 'aot_torchxla_trace_once',\n",
       " 'aot_torchxla_trivial',\n",
       " 'aot_ts',\n",
       " 'cudagraphs',\n",
       " 'dynamo_accuracy_minifier_backend',\n",
       " 'dynamo_minifier_backend',\n",
       " 'eager',\n",
       " 'eager_debug',\n",
       " 'inductor',\n",
       " 'non_leaf_compile_error_TESTING_ONLY',\n",
       " 'onnxrt',\n",
       " 'openxla',\n",
       " 'openxla_eval',\n",
       " 'pre_dispatch_eager',\n",
       " 'relu_accuracy_error_TESTING_ONLY',\n",
       " 'relu_compile_error_TESTING_ONLY',\n",
       " 'relu_runtime_error_TESTING_ONLY',\n",
       " 'torchxla_trace_once',\n",
       " 'torchxla_trivial',\n",
       " 'ts',\n",
       " 'tvm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._dynamo.list_backends(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d129c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
